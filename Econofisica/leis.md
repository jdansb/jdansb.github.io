# Leis estatísticas, modelagem baseada em agentes e econofísica
Minha intenção nesta sessão é apenas fazer um apanhado geral de como a pesquisa funciona nessa área e, em parte, o que motiva sua existência. Para quem estiver mais interessado, além das leituras já indicadas na página inicial, praticamente qualquer livro da área começa buscando oferecer uma contextualização histórica do desenvolvimento do campo.

Podemos citar obras conhecidas, como por exemplo *Essentials of Econophysics Modelling* (Slanina) e *Econophysics: An Introduction* (Sinha, Chatterjee, Chakraborti e Chakrabarti), além da obra brasileira escrita por um economista: *[Economia da complexidade: Econofísica](https://fernandonogueiracosta.wordpress.com/wp-content/uploads/2024/09/fernando-nogueira-da-costa-economia-da-complexidade-ou-econofisica-ago-2024.pdf)* (Fernando Nogueira da Costa)[^1].

## Leis estatísticas

Começamos a discussão por uma perspectiva mais geral, abordando a relação entre leis estatísticas e sistemas complexos[^2]. Atualmente, existem pesquisas em diferentes áreas que tratam seus objetos de estudo como sistemas complexos, nos quais leis estatísticas aparecem como propriedades emergentes. Este é o caso da econofísica, em que entendemos o sistema econômico como um sistema complexo, do qual emergem leis estatísticas (também conhecidas como fatos estilizados), que estudaremos mais adiante. Apesar de muitas vezes serem vistas como desconexas, essas pesquisas costumam empregar uma mesma abordagem.

Esse padrão na forma como a investigação é conduzida em diferentes casos particulares é um sinal claro de que esse conjunto de casos, na verdade, constitui uma área de investigação dotada de uma metodologia científica própria. É de conhecimento universal a importância científica do processo de identificação de padrões — uma etapa fundamental da investigação na física, como é tradicionalmente compreendida. 

Assim, a primeira conexão que podemos estabelecer entre a econofísica e o modo tradicional de fazer ciência está na centralidade do processo de identificação de padrões. Quetelet, por exemplo, já no século XIX, buscou identificar padrões em dados relativos a nascimentos, idade de casamento, atividades criminosas e taxas de mortalidade.

Antes de continuarmos, é necessário definir o que é um sistema complexo: Sistemas complexos são sistemas compostos por vários componentes microscópicos que interagem entre si, dando origem a fenômenos não triviais em escalas macroscópicas. Esses fenômenos, que não podem ser encontrados nos componentes individuais do sistema, são chamados de fenômenos emergentes, ou seja, propriedades emergentes que surgem da interação dos componentes do sistema. Na física, podemos citar como exemplo os gases como um sistema complexo e a pressão como uma propriedade emergente. A pressão do gás não é apenas o somatório da "pressão contida" em cada partícula que o compõe, mas o resultado das interações entre as partículas que formam o gás.

Dentro do contexto de sistemas complexos, esses padrões costumam ser descritos não por leis deterministas, mas por leis estatísticas. Essas leis estatísticas, por sua vez, devem ser entendidas como propriedades emergentes com características estatísticas inerentes, que podem ser produzidas em escala macroscópica a partir de modelos microscópicos de sistemas complexos.

Uma lei estatística deve ter duas características para fazer jus ao nome.  Em primeiro lugar, deve ser uma lei matemática que diferentes sistemas exibam para realmente merecer o nome de *lei*.  Em segundo lugar, deve possuir necessariamente uma natureza estatística. Ou seja, a lei se manifesta em termos de grandezas estatísticas (por exemplo: distribuições, probabilidades, médias etc.), valores que só podem ser obtidos a partir de uma grande quantidade de medidas.

Tendo delimitado o objeto de estudo (sistemas complexos que apresentam uma lei estatística como propriedade emergente), podemos caracterizar um método de investigação padrão:  
1. A descrição, em um primeiro momento, dos padrões observados no sistema por meio de leis estatísticas;  
2. O desenvolvimento e a utilização, em um segundo momento, de modelos microscópicos capazes de gerar essas leis macroscópicas.

Esta forma de fazer ciência representa um novo paradigma na investigação da realidade social. As leis estatísticas são funções com poucos parâmetros, propostas para descrever um grande conjunto de dados em diferentes cenários.  Isso permite não apenas um resumo dos dados, mas também análises analíticas e abre a possibilidade para uma análise teórica.  Os estudos das leis estatísticas não devem ser encarados como meras curiosidades; a investigação dessas leis pretende revelar as propriedades mais fundamentais do sistema estudado.

Na tradição da física social, as leis estatísticas eram vistas como semelhantes às leis empíricas da física. Assim, o termo física social estava associado à busca por comportamentos análogos a leis na sociedade, e a ideia de que existiam leis que se relacionavam com a sociedade — tal como a mecânica de Newton se relacionava com o movimento dos planetas — era compartilhada por muitos no final do século XVII. A expectativa da física social era a de que ela evoluiria como disciplina de forma semelhante ao desenvolvimento historicamente construído da mecânica clássica: observações → leis empíricas → leis universais.


Ou seja, primeiro a comunidade realiza um grande conjunto de observações e consegue extrair diversas leis empíricas pontuais dessas observações. Em seguida, a partir dessas leis empíricas, é possível abstrair leis mais gerais, que explicam tanto as leis empíricas para diferentes casos particulares quanto os dados observados. Como exemplos de leis empíricas temos Kepler e Galileu; como lei universal, temos Newton.  Embora não haja uma definição muito clara, podemos pensar que a diferença reside no escopo: enquanto as leis empíricas têm uma validade mais limitada, uma lei universal nos fornece uma descrição mais fundamental e abrangente da realidade, sendo capaz de explicar diversas leis empíricas.

Nessa perspectiva, as leis estatísticas desempenhariam o papel de leis empíricas, a etapa intermediária crucial entre as observações empíricas e o desenvolvimento de leis universais. Porém, essa analogia simplista ignora a natureza estatística fundamental das leis estatísticas, que são essencialmente diferentes da lei de Kepler.  Ainda assim, um aspecto positivo dessa visão ingênua, mantido nas aplicações contemporâneas das leis estatísticas, é a expectativa de que elas conectem observações a modelos teóricos mais gerais — ainda que não necessariamente baseados em equações.

Este modelo mais geral pode ser tanto conceitual quanto computacional (por exemplo, um modelo baseado em agentes, conforme veremos adiante). Ocupando a posição de "lei universal", podemos buscar modelos microscópicos (ou conceituais) mais gerais que consigam reproduzir (ou explicar) não apenas uma única lei estatística, mas várias.

É principalmente o uso combinado das leis estatísticas e dos modelos microscópicos dos sistemas complexos que caracteriza a investigação da distribuição de riquezas na econofísica, da forma como é trabalhada hoje.  Há três mudanças que merecem ser destacadas na forma como se trabalhava com sociofísica e que foram causadas pela adesão à abordagem dos sistemas complexos:

1. Não ver as leis estatísticas como um simples efeito independente de influências aleatórias, que se espera encontrar em partes isoladas do sistema, mas sim como uma propriedade emergente de um sistema complexo.
2. O interesse nas leis vai além das aplicações práticas ou discussões filosóficas; elas são motivações e justificativas para a proposição de modelos mecanísticos dos fundamentos microscópicos do sistema.
3. A explicação teórica das leis não segue o paradigma da mecânica clássica, mas o da mecânica estatística, isto é, baseada em modelos probabilísticos.

### Formalização

Uma lei estatística (em sistemas complexos) é uma função que:
1. Foi proposta para descrever um grande número de observações em diferentes cenários (universalidade);
2. É elementar ou uma composição de funções elementares com um pequeno número de parâmetros e dimensões (simplicidade);
3. Desempenha um papel importante em uma teoria ou modelo (conexão teórica).

Tipicamente, uma lei estatística se aplica a um conjunto de dados e descreve a frequência de observação de alguma coisa ou a relação entre duas propriedades do sistema observado. A universalidade expressa nossa intenção de que a lei seja válida para todos os casos similares, não se restringindo apenas a alguns casos particulares.  A simplicidade pode ser colocada de forma matemática, dizendo que a dimensão das funções deve ser muito menor que o número de observações. Há uma ideia implícita de que se deve buscar a menor quantidade possível de parâmetros visando a simplicidade — não queremos simplesmente ajustar uma curva aos dados. Por fim, essas leis possuem um papel central ao servir como conexão teórica entre os dados observados e modelos microscópicos, que devem fornecer uma explicação mecanicista da lei e/ou ser usados em uma teoria mais geral sobre os fundamentos desse sistema.

Antes de concluir esta sessão, uma breve justificativa sobre por que temos a ideia de que existe algo que podemos generalizar como leis estatísticas. Isso decorre da observação de que diferentes leis estatísticas parecem ser motivadas, justificadas, usadas e estudadas de forma semelhante. De forma geral, a forma de raciocinar com as leis estatísticas segue uma sequência de três passos conectados.

* **Definição e validação**: Começamos com uma análise empírica. O passo inicial é, inevitavelmente, análogo a toda ciência: a análise de um grande conjunto de observações. É neste momento que observamos algum padrão nos dados e propomos uma lei estatística. Também é nesse momento que testamos a validade da lei proposta em outros conjuntos de dados. Evidentemente, esse passo passa por diversas reformulações, generalizações, modificações e toda a sorte de processos científicos tradicionais.

A partir desse passo, os próximos dois passos acontecem de forma paralela; isto é, em posse da lei estatística proposta no passo anterior, temos dois caminhos a percorrer:

* **Explicação da lei**: A explicação da lei estatística passa pelo desenvolvimento de um modelo generativo, isto é, um modelo capaz de gerar uma distribuição que obedeça à lei estatística. Após considerar que a lei estatística é empiricamente válida, uma questão óbvia a ser investigada é sua origem. Para isso, propomos modelos mecanísticos simples que gerem observações que satisfaçam as leis estatísticas.

* **Consequências da lei**: Uma segunda pergunta que surge após considerarmos que a lei estatística é válida é quais são as consequências dessa lei. Trata-se de uma extrapolação das suas consequências para além do que observamos até então — isto é, predições baseadas na própria lei, na sua relação com outras leis, no uso dessa lei como restrição em outros modelos, etc. A capacidade preditiva de uma lei é frequentemente considerada o objetivo principal em uma pesquisa tradicional.

Essencialmente, o que fazemos é associar uma lei estatística (macroscópica) necessariamente a um modelo generativo (microscópico), adotando esse método como a forma padrão de trabalho.  Podemos notar, então, que as investigações nessa área têm três elementos fundamentais:
1. Um sistema complexo a ser investigado;
2. Uma lei estatística emergente desse sistema;
3. Um modelo generativo capaz de reproduzir a lei estatística em nível macroscópico, a partir de regras microscópicas.

Eu adoto como conceito de modelagem, para a construção do modelo generativo, a modelagem baseada em agentes. Por isso, abordaremos esse conceito na próxima sessão. Também vale comentar brevemente que essa abordagem moderna de fazer ciência só se torna possível quando há dados suficientes sobre as sociedades, que nos permitam propor e testar leis estatísticas, e poder computacional suficiente para implementarmos os modelos. Ou seja, trata-se necessariamente de um fruto do nosso tempo.

## Modelagem baseada em agentes (MBA)

De forma geral, um modelo é sempre uma abstração da realidade — uma representação simplificada que preserva uma equivalência adequada para determinadas situações, podendo ser visto como uma visão substitutiva da realidade, com o objetivo de facilitar o raciocínio.

Uma vez que, por meio dos modelos, buscamos simular a realidade, a eficiência de um modelo depende da correta tradução da realidade para o modelo. Por isso, é importante refletir sobre o modelo antes mesmo do ato de modelagem começar. É necessário identificar as variáveis relevantes para o problema que será abordado e definir a linguagem que será utilizada, pois a elaboração do modelo depende desses pontos cruciais[^3].

Uma vez que o modelo é uma simplificação da realidade, é possível que uma mesma realidade seja modelada de diferentes formas, já que nenhum modelo é a realidade em si. Um exemplo é a forma mais tradicional de modelos científicos na física: os modelos baseados em equações diferenciais — em português, modelo baseado em equações (MBE); em inglês, *equation-based model (EBM)*. Outra forma de modelagem, que tem se tornado cada vez mais popular, são os modelos baseados em agentes (MBA) — em inglês, agent-based models (ABM). Essa é uma abordagem de modelagem computacional na qual a dinâmica de um sistema complexo é representada em termos dos agentes e de suas interações.

Os agentes são indivíduos computacionais autônomos que possuem propriedades e regras de comportamento que regem sua interação com outros agentes e com o ambiente. Lembrando que sistemas complexos são definidos como sistemas compostos por múltiplos elementos individuais que interagem entre si e apresentam um comportamento que não pode ser previsto apenas a partir dos próprios elementos. O resultado dessas interações é o surgimento de um fenômeno emergente. O fenômeno emergente possui necessariamente duas características essenciais:
1. **Irredutibilidade**: As estruturas que emergem não podem ser deduzidas apenas das propriedades dos elementos individuais, pois surgem das interações entre eles. Ou seja, são propriedades do sistema como um todo, e não dos elementos isolados que o compõem.
2. **Auto-organização**: O fenômeno surge espontaneamente, sem a presença de um coordenador central.
3. A emergência pode, assim, ser compreendida como o processo que mantém a estrutura do sistema.

A proposta central da modelagem baseada em agentes é a de que a maioria dos fenômenos do mundo real pode ser efetivamente modelada com três elementos: agentes, um ambiente e uma descrição das interações agente-agente e agente-ambiente. O objetivo desse tipo de modelagem é, então, criar agentes e regras que gerem o comportamento desejado — que, no nosso contexto, são os descritos por leis estatísticas. Uma vez criado, esse sistema pode ser utilizado para obter um melhor entendimento do fenômeno modelado, por meio da experimentação com diferentes regras e propriedades, visando testar diferentes hipóteses.

Há 8 principais usos para um modelo baseado em agentes[^4]:

1. **Descrição**: descreve de maneira simplificada um sistema do mundo real.
2. **Esclarecimento**: aponta os principais mecanismos envolvidos em um fenômeno.
3. **Experimentação**: pode ser executado repetidamente, permitindo variar os parâmetros para observar seus efeitos no comportamento do sistema como um todo e nos resultados gerados.
4. **Previsão de fontes de analogia**: é possível encontrar similaridades com outras simplificações, mesmo que estejam modelando fenômenos aparentemente muito diferentes.
5. **Comunicação / Educação**: pode ser utilizado para que pessoas explorem e compreendam melhor determinados fenômenos, mesmo sem dominar todos os detalhes do modelo, facilitando o aprendizado.
6. **Prover peças centrais para o diálogo científico**: também chamado de "objeto com que pensar", quando comparado com modelos textuais, elimina ambiguidades de interpretação e permite discutir, de forma mais objetiva, quais mecanismos são relevantes para gerar determinado comportamento — por meio da remoção ou adição controlada de mecanismos no modelo.
7. **Experimento mental**: não precisa necessariamente representar um fenômeno do mundo real; pode ser restrito a um experimento conceitual.
8. **Projeção de padrões futuros**: a partir da descrição de padrões passados, espera-se que seja possível explicar ou antecipar padrões futuros que possam surgir.

Uma vez que o MBE é a abordagem com a qual físicos e cientistas, em geral, estão mais habituados a modelar sistemas, torna-se natural fazermos uma rápida comparação entre ambas as estratégias de modelagem: MBE (modelo baseado em equações) e MBA (modelo baseado em agentes). O primeiro ponto é que os MBAs podem modelar populações heterogêneas de agentes com facilidade, enquanto os MBEs geralmente partem da hipótese de homogeneidade. Em muitas áreas, no entanto, a heterogeneidade desempenha um papel central no comportamento do sistema.

Outra vantagem da abordagem MBA é que, enquanto para modelar com equações precisamos ter um bom conhecimento fenomenológico dos mecanismos internos do sistema de interesse, nos MBAs basta conhecermos as regras em nível individual — o que, em geral, é mais direto de se obter. Um grande risco no processo de modelagem, de modo geral, é modelarmos os efeitos em vez das causas. Pela natureza mais direta da abordagem em nível individual dos MBAs, partimos exatamente da ideia de modelar as interações entre os agentes, de modo que o fenômeno emergente de interesse seja o resultado do sistema. Isso nos permite, de forma natural, focar nas causas para compreender os efeitos.

Os resultados de um MBA também tendem a ser mais detalhados, uma vez que suas saídas não se limitam ao nível do sistema como um todo, mas também incluem informações no nível individual. A modelagem baseada em agentes permite manter um histórico das interações entre os agentes, e esse histórico pode ser usado para que o agente altere seus comportamentos e estratégias com base em eventos passados.  Isso torna a abordagem uma ferramenta muito útil para modelar interações complexas entre agentes adaptativos. Devido à forma como os ABMs são construídos, novas regras de interação podem ser adicionadas, removidas ou alteradas com relativa facilidade.

Outra diferença importante é que, enquanto um MBA representa resultados naturalmente discretos e frequentemente com flutuações, um MBE fornece uma representação contínua e sem ruído. Naturalmente, há situações em que o custo de construir um ABM excede seus benefícios. Resultados mais detalhados são obtidos com modelos mais complexos, que exigem maior poder de processamento. De maneira geral, ABMs são computacionalmente mais pesados do que EBMs, uma vez que estes últimos são relativamente simples, frequentemente consistindo em um pequeno conjunto de equações que podem ser resolvidas numericamente ou até mesmo analisadas em torno dos pontos de equilíbrio. Em geral, se o problema envolve um grande número de agentes homogêneos, será possível obter uma solução mais precisa e em menor tempo utilizando uma abordagem baseada em equações. Portanto, esse problema pode ser melhor modelado por essa categoria de modelos.
 
Como pode-se perceber, modelagem baseada em agentes é mais um conceito para a construção de um modelo que uma receita. Aescolha entre ABM e EBM depende de o que e como queremos modelar, não há um método intrinsecamente superior ao outro. Dentro do contexto que estamos discutindo, de sistemas complexos e leis estatísticas, estamos interessados em uma modelagem a nível microscópico que consiga ser capaz de gerar a lei estatística como uma propriedade emergente do sistema, desta forma nos é mais adequado utilizarmos ABM.

Como se pode perceber, a modelagem baseada em agentes é mais um conceito para a construção de um modelo do que uma receita pronta. A escolha entre ABM e EBM depende do que e como queremos modelar; não há um método intrinsecamente superior ao outro. Dentro do contexto que estamos discutindo, de sistemas complexos e leis estatísticas, nosso interesse é por uma modelagem a nível microscópico capaz de gerar a lei estatística como uma propriedade emergente do sistema.  Dessa forma, é mais adequado utilizarmos ABM.

Uma vez que construímos um modelo satisfatório, um dos papéis mais importantes da modelagem é a simulação, pois é por meio dela que podemos determinar o quanto o modelo se aproxima da realidade. A partir do momento em que alcançamos um grau de fidelidade aceitável no aspecto que o modelo se propõe a representar, podemos criar situações que são difíceis de serem observadas e estudadas no mundo real, de forma que o modelo possa ser utilizado também como ferramenta de tomada de decisão.

Antes de avançarmos, vale comentar que estes modelos são sempre sugestivos. Isto é, eles apenas demonstram que um dado fenômeno não é inconsistente com as consequências da lógica computável do nosso modelo. Não podemos saber se não há um modelo ainda mais simples que consiga reproduzir o mesmo fenômeno, mas podemos saber que não é preciso um modelo mais complexo [^5].

## Econofísica

Uma vez que entendemos a relação entre sistemas complexos e leis estatísticas, e compreendemos o conceito de modelagem utilizado para gerar os modelos generativos, podemos discutir rapidamente o que é a econofísica.

Augusto Comte, no começo do século 19, foi o responsável por cunhar o termo "física social" como uma referência explícita ao sucesso da mecânica newtoniana. Apesar de ter abandonado o termo posteriormente, ele foi recuperado mais tarde por seus sucessores, particularmente Adolphe Quételet, astrônomo por formação, que publicou em 1835 um ensaio sobre física social. Outro intelectual influente para o desenvolvimento da área foi o historiador Henry Buckle, responsável por apresentar uma abordagem estatística da história da civilização.

Entre esta lista de ilustres nomes, podemos citar também Friedrich Engels[^6], ainda no século 19, postulou que, apesar de cada indivíduo ter sua vontade pessoal, as múltiplas vontades individuais existentes em uma sociedade se entrecruzam e até mesmo conflitam entre si. Do choque dessas vontades, obteríamos um estado análogo ao que encontramos na natureza desprovida de consciência. Essa constatação abre a possibilidade de modelarmos fenômenos sociais com ferramentas análogas às utilizadas nas ciências naturais.

Na mesma época de Quételet, Georg Graf contemplou aplicar os princípios da mecânica clássica especificamente à economia. Seu conhecimento da física newtoniana era profundo, e ele contribuiu para diversas áreas da ciência.  Um texto seu de 1815 já apresentava o que poderia ser considerado um capítulo de um livro de economia, referindo-se explicitamente à mecânica clássica — uma forma de pensar revolucionária para sua época.

Na segunda metade do século 19, uma tentativa similar foi feita por Vilfredo Pareto. Pareto também se voltou à economia munido de um bom conhecimento da mecânica clássica newtoniana e com entusiasmo em descrever movimentos sociais da mesma forma que se descrevia o movimento dos planetas. Ele chegou a comparar as leis de Kepler a leis econômicas que ainda estariam por ser descobertas. A lei de Pareto sobre a distribuição da riqueza tornou-se uma peça fundamental do conhecimento econômico. No entanto, sua ambição de reduzir as leis econômicas a algo análogo às leis de Newton perma

Os métodos de probabilidade e estatística floresceram primeiro entre os cientistas sociais que investigavam regularidades quantitativas no funcionamento da sociedade.  Somente em um segundo momento a física se move do determinismo da física newtoniana em direção à descrição probabilística dos gases ideais, apropriando-se então das ferramentas estatísticas já existentes. É notável como esses conceitos, desenvolvidos inicialmente fora da física, acabaram por influenciar diretamente o próprio desenvolvimento da disciplina. Se, nos dias atuais, os físicos recorrem à analogia entre moléculas e humanos para investigar questões sociais, Boltzmann tinha em mente uma analogia similar — mas invertida — ao investigar os gases, inspirando-se na sociedade para analisar um fenômeno tipicamente físico. Em um trecho de seu artigo de 1872, ele menciona:

> “As moléculas são como muitos indivíduos, tendo os mais diversos estados de movimento, e as propriedades dos gases permanecem inalteradas só porque o número destas moléculas, que em média têm um dado estado de movimento, é constante.”

Na história do desenvolvimento da econofísica, um marco decisivo na discussão sobre a interação entre física e economia foi a introdução do conceito de fractais por Benoit B. Mandelbrot. Outro momento relevante foi a conferência programada para ocorrer em Moscou em 1974, cuja organização incluía nomes como Kenneth Arrow (laureado em economia) e Hans Bethe (laureado em física).  Apesar de ter sido cancelado, o evento desempenhou um papel significativo na transferência de ideias e da linguagem da física para outras áreas do conhecimento humano. Seus manuscritos sobreviveram, e alguns foram publicados posteriormente, influenciando diretamente o desenvolvimento futuro da econofísica.

Após esse evento, outras tentativas de integrar a física com outras disciplinas começaram a florescer ainda mais intensamente. Entre as décadas de 1970 e 1980, a ciência da complexidade ganhou enorme popularidade, com o Instituto Santa Fé desempenhando um papel ativo nesse processo.  Foi nesse contexto que a teoria de sistemas complexos começou a ser aplicada de forma sistemática à economia. O físico laureado P. W. Anderson passou a se envolver profundamente com essa linha de pesquisa, promovendo ativamente o uso de métodos da física em problemas sociais e econômicos. Em 1991, a revista *Physica A* publicou o que hoje é considerado o primeiro artigo que pode ser verdadeiramente atribuído ao recém-nascido campo da econofísica.

Mas o que é exatamente econofísica ainda é uma questão em aberto — não há um consenso claro. Para Slanina, ela não é uma simples mistura entre as ciências naturais e a economia, tampouco uma ciência interdisciplinar entre economia e física[^7].  Ele prefere chamá-la de transdisciplinar, pois o objetivo não é ocupar um lugar entre as disciplinas, mas sim encontrar princípios que sejam verdadeiros em ambas. Ou seja, trata-se de uma busca por princípios comuns, ferramentas compartilhadas e consequências equivalentes.

Outro ponto relevante para a discussão é a forma como os econofísicos direcionam seus esforços. A econofísica não se resume a pegar um fragmento da física teórica e reinterpretá-lo na linguagem da economia. Um relatório[^8] de 2022 sobre física social adota uma definição mais ampla que a de Slanina: física social é uma coleção de tópicos de pesquisa voltados para a resolução de problemas sociais, nos quais cientistas com formação formal em física têm contribuído e continuam a contribuir significativamente. Embora definições mais abertas frequentemente gerem debate, trata-se aqui de uma definição pragmática, baseada na ideia de que o que os físicos realmente fazem é o que define o que é física.

O enorme sucesso da física ao longo do último século levou cientistas de outras disciplinas a tentar formular métodos quantitativos similares aos da física.  De maneira geral, isso resultou em uma proliferação de modelos matemáticos e físicos em diversas áreas do conhecimento. E então, se vamos utilizar métodos análogos aos da física, quem melhor do que os próprios físicos para contribuir?  Dessa forma, opta-se por chamar de física social essa coleção de tópicos que têm por objeto de estudo problemas sociais, com físicos como os principais profissionais envolvidos. 

Apesar de a física social não ser algo novo, essa tendência ressurge com mais intensidade nos tempos atuais. Isso ocorre não apenas devido aos avanços recentes na tecnologia necessária para sua implementação, mas também como resultado de uma diminuição no ritmo do progresso científico da física tradicional, ao menos em comparação com o século anterior. Esse fenômeno gera, por um lado, o movimento de físicos em busca de uma "nova física", e por outro, o de jovens cientistas que decidiram empregar suas habilidades quantitativas em outros tópicos.

Os temas da física social muitas vezes surgem de uma reflexão sobre o que constitui e sustenta o modo de vida moderno, e também sobre o que o perturba ou ameaça. A prosperidade das cidades está, em muitos aspectos, atrelada aos mercados, e a economia tem um impacto profundo no desenvolvimento e no planejamento da vida urbana. É nesse contexto que emerge, de forma mais específica, o campo da econofísica.

Diferentemente da economia tradicional, que está construída sobre um modelo de escolhas racionais, a econofísica se destaca por, inicialmente, tomar emprestado o modelo de partículas da física estatística para explicar o comportamento dos agentes. Essa forma de modelagem assume que os interesses e preferências dos agentes não são fixos, mas dependem da interação com outros agentes. Colocando de outra forma, a econofísica coloca uma grande ênfase no ambiente social do agente.
 
A econofísica tradicionalmente tem focado em questões como o fluxo de dinheiro e os mercados financeiros, devido à existência de um grande conjunto de dados disponíveis, que permitiu a aplicação eficaz de ferramentas e métodos da física estatística nessas áreas. Áreas como a macroeconomia historicamente não atraíram a atenção dos econofísicos. Porém, com o crescimento da área, o aumento da disponibilidade de dados e o avanço do poder computacional nos últimos anos, os econofísicos podem desempenhar um papel importante no futuro do desenvolvimento da macroeconomia.


Além disso, pode-se mencionar que empreendimentos interdisciplinares dessa natureza contribuem para aproximar as ciências naturais** e as ciências humanas. Como disse Karl Marx[^9]: 

> "Conhecemos uma única ciência, a ciência da história. A história pode ser examinada de dois lados, dividida em história da natureza e história dos homens. Os dois lados não podem, no entanto, ser separados; enquanto existirem homens, história da natureza e história dos homens se condicionarão reciprocamente."

Lembrando que, por história da natureza, segundo o próprio autor, referimo-nos às ciências da natureza.

[^1]: Também há um artigo de divulgação científica interessante intitulado *[A física das partículas humanas](https://cienciahoje.periodicos.capes.gov.br/storage/acervo/ch/ch_342.pdf)* (Celia Anteneodo).
[^2]: A discussão completa pode ser encontrada no livro [*Statistical Laws in Complex Systems*](https://arxiv.org/abs/2407.19874) (Altmann).
[^3]: [*Em busca da Aplicabilidade de Sociedades Artificiais em Informática Educativa*](https://lume.ufrgs.br/bitstream/handle/10183/12181/000617438.pdf?sequence=1&isAllowed=y) (Henrique Oliveira da Silva) e *[Otimização combinatória e programação linear: Modelos e algoritmos](https://web.ist.utl.pt/luis.tarrataca/classes/linear_programming/OtimizacaoCombinatoriaeProgramacaoLinear.pdf)* (Marco Goldbarg) servem de referência para esta discussão sobre modelos.
[^4]: A discussão completa pode ser encontrada no livro *An Introduction to Agent-Based Modeling* (Wilensky e Rand).
[^5]: Comentário originalmente encontrado no *Classical Econophysics* (Cottrell, Cockshott, Michaelson e Wright).
[^6]: *Anti-Dühring* (Friedrich Engels).
[^7]: *Essentials of Econophysics Modelling* (Slanina)
[^8]: *[Social physics](https://www.sciencedirect.com/science/article/abs/pii/S037015732100404X)*.
[^9]: *A ideologia Alemã* (Friedrich Engels e Karl Marx)
